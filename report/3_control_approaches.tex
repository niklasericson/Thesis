% !TEX root = main.tex
\chapter{Theory}\label{cha:modelling}
This chapter presents the motivation and the theory behind each of the control approaches investigated in this thesis.

\section{Model Reference Adaptive Control}
An adaptive controller has the ability to adjust the system repsonse by updating the parameters of a feedback controller in real time, resulting in a controller that is less sensitive to changes in the model and aging of the system. One approach is to use a reference model to create the desired system response which the adaptive laws will aim for, this approach is known as the Model Reference Adaptive Controller (MRAC). This model does not require any prior knowledge about the model uncertainties, implying in a more straight forward way to implement precision control to nanopositioning systems. Moreover, this scheme allows for the use of a lower order model (in relation to the system model) since the online parameter estimation can be used sufficiently with a lower order model. The MRAC scheme can be extended to include perturbation estimation (MRACPE), giving the controller the ability to compensate for various unmodelled effects, including both linear and nonlinear perturbations. Nonlinear effect such as the hysteresis are treated as lumped perturbations to the nominal system model and can be compensated for in the same manner as linear, using the knowledge of the system and the previous measurement and output signal. The MRACPE also allows the maximum tracking error to be predefined.

\subsection{Perturbation Estimation}\label{sec:pertest}
Using a second order model, the adaptive laws can be derived as follows. Consider the system model stated below.
\begin{equation}
  \label{eq:sysmodel}
  \ddot{x}(t) + \alpha_1\dot{x}(t) +  \alpha_0x(t) = \beta_0u(t) + f(t)
\end{equation}

where $x(t)$ denotes the output rotation at time t, $u(t)$ the input voltage at time t and $\alpha_1, \alpha_0, \beta_0 \in \mathbb{R}$ are known system constants. $f(t)$ is a function describing the unknown perturbations of the system, including the hysteresis and creep effect. The general equations for deriving the perturbation function are described more thoroughly in~\cite{Elmali:1996}, for a simple second order SISO model the perturbation estimation is derived to

\begin{equation}
  \label{eq:perturbation}
  \hat{f}(t) = \ddot{x}_{cal}(t) + \alpha_1\dot{x}_{cal}(t) +  \alpha_0x(t) - \beta_0u(t-T_s)
\end{equation}

where $x_{cal}^{(n)}$ denotes the calculated state, $T_s$ is the sampling time interval and $u(t-T_s)$ is the control input in the previus timestep. $u(t-T_s)$ is often approximated to $u(t)$ in practice which is valid approximation if $T_s$ is sufficiently small. Denote that $x(t)$ here is the sensor input, i.e. the measured yaw angle.

Each state is, for its computational efficiency, computed by a simple backward different equation depicted below.

\begin{equation}
  \label{eq:backward}
  x_{cal}^{(n)}(t) = \frac{x_{cal}^{(n-1)}(t) - x_{cal}^{(n-1)}(t-T_s)}{T_s}
\end{equation}

\subsection{Adaptive laws}
The objective of the adaptive laws is to calculate the control parameter so that they converges to ideal values resulting in a system response that matches the reference. The adaptive laws can be derived using Lyaponov theory which is outlined in this section. Consider the second order reference model below

\begin{equation}
  \label{eq:refmodel}
  \ddot{x}_m(t) + a_1\dot{x}_m(t) +  a_0x_m(t) = b_0u_d(t)
\end{equation}

where $x_m(t)$ denotes the output rotation, $u(t)$ the input voltage and $a_0, a_1, b_0$ are known positive constants.

The tracking error is defined as below.
\begin{equation}
  \label{eq:stateerror}
  e(t) = x(t) - x_m(t)
\end{equation}

Recalling~\eqref{eq:sysmodel}, replacing $f(t)$ with the estimation $\hat{f}(t)$ and subtracting it from~\eqref{eq:refmodel} gives the following expression, more details can be found in~\cite{Qingson:2016}.

\begin{equation}
  \ddot{e}(t) + a_1\dot{e}(t) + a_0\dot{e}(t) =  (a_1-\alpha_1)\dot{x}(t) + (a_0-\alpha_0)x(t) - b_0u_d(t) - \beta_0u(t) + \hat{f}(t)
\end{equation}

Transforming it into state-space form
\begin{equation}
  \label{eq:refmodel}
  \mathbf{\dot{E} = AE} + \beta_0\mathbf{B}u + \Delta
\end{equation}
where
\begin{equation}
  \label{eq:matrices}
  \mathbf{E} =
    \begin{bmatrix}
       e\\[0.3em]
       \dot{e}
     \end{bmatrix},
  \mathbf{A} =
    \begin{bmatrix}
       0 & 1\\[0.3em]
       -a_0 & -a_1
     \end{bmatrix},
  \mathbf{B} =
    \begin{bmatrix}
        0\\[0.3em]
        1
    \end{bmatrix},
    \mathbf{\Delta} =
      \begin{bmatrix}
          0\\[0.3em]
          \delta
      \end{bmatrix}
\end{equation}
with $\delta = (a_1-\alpha_1)\dot{x}(t) + (a_0-\alpha_0)x(t) - b_0u_d(t) + \hat{f}(t)$.

If all the eigenvalues of A have negative real parts, then $\mathbf{E}$ will tend to zero as  $t \to \infty$, i.e. the system is asymptotically stable. Morover, according to Lyaponov  theory \cite{Ljung:2003}, for each positive-semidefinite matrix Q, there exist one positive-semidefinite matrix P which solves \eqref{eq:lyap}.

\begin{equation}
  \label{eq:lyap}
  \mathbf{A^TP + PA = -Q}
\end{equation}

With the auxillary item $\hat{e} = \mathbf{E^TPB}$, the adaptive laws is given by

\begin{equation}
  \label{eq:adaplaws}
  u = k_0u_d + k_1x + k_2\dot{x} + k_3\hat{f}
\end{equation}
where the control law parameters is calculated as
\begin{equation}
  \label{eq:adaplaws1}
  \dot{k_0} = -\eta_0\hat{e}u_d
\end{equation}
\begin{equation}
  \label{eq:adaplaws2}
  \dot{k_1} = -\eta_1\hat{e}x
\end{equation}
\begin{equation}
  \label{eq:adaplaws3}
  \dot{k_2} = -\eta_2\hat{e}\dot{x}
\end{equation}
\begin{equation}
  \label{eq:adaplaws4}
  \dot{k_3} = -\eta_3\hat{e}\hat{f}
\end{equation}

the proof is provided in \citep{Qingson:2016}. Substituting $\hat{f}$ in \eqref{eq:perturbation} with the one in \eqref{eq:adaplaws} and rearranging the parameters results in the final MRACPE control law, stated below.

\begin{equation}
    \label{eq:adaplawsfinal}
  u(t) = k_0u_d(t) + (k_1 + k_3\alpha_0)x(t) +  (k_2 + k_3\alpha_1)\dot{x}(t) + k_3\ddot{x}(t) - k_3\beta_0u(t-T_s)
\end{equation}

A block diagram of the final controller, with inspiration from Figure 9.1 in ~\citep{Qingson:2016}, is depicted in Figure~\ref{fig:adaptive}. The adaptive controller consists of 4 blocks. One reference model that calcultats the desired states $Xm=[\dot{x}_m, x_m]^T$ from the input signal according to \eqref{eq:refmodel}, one adaptive mechanism that implements \eqref{eq:adaplaws1}-\eqref{eq:adaplaws4} and calculates $K=[k_1, k_2, k_3, k_4]^T$, one state calculator that uses \eqref{eq:backward} to calculate $X=[\ddot{x}, \dot{x}, x]^T$ and finaly one controller block that uses \eqref{eq:adaplawsfinal} to calcuate the control signal $u$ that is sent to the rotaional stage.

\begin{figure}[h]
  \centering %crop: left bottom right top
  \includegraphics[width=0.7\textwidth, trim=4cm 0cm 3.8cm 0cm, clip=true]{fig/matlab/adaptive_scheme}
  \caption{\label{fig:adaptive}Block diagram of the adaptive controller}
\end{figure}

\section{Integral Resonance Control}\label{sec:irc}
The integral resonace control (IRC) can be efficiently used to damp out the first resonant mode of the system, allowing for larger controller gains and a higher control bandwidth. The \abbrIRC scheme is illustrated in Figure~\ref{fig:irc} and consist of a constant artificial feed-through term $D_f<0$ and an integral controller $C=\frac{k}{s}$. The negative feed-forward term will, if sufficiently large and negative, introduce a pair of complex zeros below the first resonance frequency and ensure zero-pole cancellation for higher resonance modes as shown in \citep{Aphale:2007}. For stability, the phase response of the loop-gain $CG_d$ must be within $\pm180^{\circ}$ while the gain is greater than 0. The negative sign in $G_d$ subtracts a phase of $-180^{\circ}$. Using this knowledge, the phase margin can be easily increased by applying a simple negative integral controller to provide a 90 degrees phase lead. This results in a phase margin between  $\pm90^{\circ}$ which gives the system highly desired properties such as a $90^{\circ}$ phase margin and an infinite gain margin.

The negative gain $D_f$ is straight forward to manually select for introducing a complex pair of zeros below the first resonance. The integral gain $k$ can be chosen by using the root locus technique and select a gain that maximizes damping.

\begin{figure}[h]
  \centering %crop: left bottom right top
  \includegraphics[width=1\textwidth, trim=5.5cm 3cm 5.1cm 9.5cm, clip=true]{fig/matlab/irc}
  \caption{\label{fig:irc}Block diagram of IRC damping loop}
\end{figure}

The IRC scheme in Figure~\ref{fig:irc} can be simplified, by combining $C$ and $D_f$ in the same block, the resulting scheme is shown in the inner loop in Figure~\ref{fig:irc_int}, where

\begin{equation}
  \label{eq:C2}
  C_2 = \frac{C}{1+CD_f}
\end{equation}

For tracking reference trajectories, the IRC can be enclosed in an outer loop, also seen in Figure~\ref{fig:irc_int}, utilizing a second controller $C_1$ to compensate for disturbances and model errors. For the outer controller $C_1$, a PI controller is sufficient but must include a negtive gain to compensate for the inversion that is caused by $D_f$ \citep{gu:2014}.

\begin{figure}[h]
  \centering %crop: left bottom right top
  \includegraphics[width=1\textwidth, trim=4cm 5cm 3.6cm 9.5cm, clip=true]{fig/matlab/irc_int}
  \caption{\label{fig:irc_int}Block diagram of the tracking control system with IRC included}
\end{figure}

Proof for the zero-pole interlacement and the insertion of the complex conjugate zeros can be found in \citep{Aphale:2007}, but note that the proof is only given for causal systems with a relative degree of two i.e two more poles than zeros. To give the reader further information about the \abbrIRC and for a system with a relative degree of one, a brief example of a low order system is provided below.

Let G be represented as a transfer function with a relative degree of one, with 2 poles and 1 zero as written below,

\begin{equation}
  \label{eq:irc_sys}
  G = \frac{s + \alpha_0}{s^2 + \beta_1s + \beta_0}
\end{equation}

where  $\alpha_i > 0$ and  $\beta_i > 0$, i.e. a stable and minimum phase system.  Using $G_d = G + D_f$  ~\eqref{eq:irc_sys} and rearranging the terms gives

\begin{equation}
  \label{eq:irc_sys_d}
  \begin{split}
  G_d & = \frac{s + \alpha_0}{s^2 + \beta_1s + \beta_0} + D_f \\
      & = \frac{D_fs^2 + (1 + D_f\beta_1)s + \alpha_0 + D_f\beta_0}{s^2 + \beta_1s + \beta_0} \\
      & = \frac{D_f(s^2 + (\frac{1}{D_f} + \beta_1)s + \frac{\alpha_0}{D_f} + \beta_0)}{s^2 + \beta_1s + \beta_0}
  \end{split}
\end{equation}

which illustrates that the number of introduced zeros is equal to the relative degree of the transfer function and that the zeros ($s^z_i$) will have a negative real part if the following conditions are fulfilled.

\begin{equation}
  \label{eq:irc_cond}
  Re(s^z_i) < 0 \quad \text{if }
  \begin{cases}
    D_f < -\frac{1}{\beta_1}\\
    D_f < -\frac{\alpha_0}{\beta_0}\\
  \end{cases}
\end{equation}

\section{Harmonic cancellation}
Cancellation of specific harmonics can be utilized to increase the tracking capability of the controller. A known or estimated disturbance can be in many cases be efficiently eliminated by a number of methods, \citep{fujimoto2009rro} \citep{fujimoto2004repetitive} \citep{vilanova2008disturbance}. Many of these approaches are based on the Internal Model Principle (\abbrIMP), using an internal model to simulate the system response and to estimate the behavior of an applied disturbance. However including the disturbance model for effective cancellation in the feedback loop will deteriorate the sensitivity function making the system more sensitive to other frequencies. Hence, a feedforward approach is preferable to preserve the fine closed loop characteristics. This approach aims to cancel the periodic disturbances that are introduced by the movement of the linear stage. The introduced frequencies are even known before operation since they easily can be calculated from the stepping rate of the linear axis motor.

\subsection{Feedforward from modeled disturbance}
If a disturbance is known and measurable during operation, a feedforward of the disturbance model response can be used to eliminate the disturbance before it gets present in the output signal \citep{industrial}. A simple block diagram of the structure is shown in Figure~\ref{fig:ffdist}, where $G, C, P_d$ and $K_f$ represents the system, the controller, the disturbance model and the feedforward block respectively.

\begin{figure}[h]
  \centering %crop: left bottom right top
  \includegraphics[width=1\textwidth, trim=8cm 4.5cm 5.97cm 8cm, clip=true]{fig/matlab/ffdist}
  \caption{\label{fig:ffdist}Block diagram of a control structure with feedforward from a known modeled disturbance.}
\end{figure}

The output is described by the following expression

\begin{equation}
  \label{eq:ffdist}
  Y = \frac{CG}{1+CG}R + \frac{P_d - K_fG}{1+CG}D_0
\end{equation}

and hence a ideal choice of $K_f$ would be $Kf=P_d/G$ which would eliminate the disturbance completely. It is worth noting that the ideal $K_f$ might not be fully implementable (stable, proper and causal) and that the inverse of G has to be approximated, leading to solely partial cancellation of the disturbance. This approximation can still be sufficient if the inverse is constructed in a way so that $(P_d - K_fG)/(1+CG)$ becomes small for the frequencies where the disturbance has the most impact on the system.

\subsection{Repetitive feedforward disturbance cancellation}
Repetitive control can sufficiently be used to track and reject periodic disturbances with relatively long periods. For higher frequency modes it fails to do so due to a number of reasons but mostly for the inclusion of a low-pass filter which is needed for maintaining stability \citep{fujimoto2009rro}. The conventional repetitive approach uses the \abbrIMP to include the discrete time disturbance model in the feedback controller and although the sensitivity function is zero for the selected frequencies, it is increased for the other nearby frequencies, leading to severe damage in the total tracking accuracy. This phenomenon can be explained by Bode's integral constraints \citep{Ljung:2003}. With respect to this drawback, a novel control scheme with a feedforward switching mechanism and an observer was introduced by the authors in \citep{fujimoto2004repetitive}, for the purpose of head-tracking control in hard disk drives. A block scheme of the novel control scheme is presented in Figure~\ref{fig:ffrep}, where $G$ and $C$ represents the system and the feedback controller as before. The output disturbance and the observed and replicated compensation signal are denoted $d_o$ and $d_i$, respectively.

\begin{figure}[h]
  \centering %crop: left bottom right top
  \includegraphics[width=1\textwidth, trim=6cm 5.5cm 5.2cm 3cm, clip=true]{fig/matlab/ffrep}
  \caption{\label{fig:ffrep}Block diagram of the feedforward switching mechanism including observer and feedback controller.}
\end{figure}

This method uses an observer to estimate the states of a disturbance. When the states has converge the switch is turned on for one period $T_d$ of the disturbance. This period is then replicated and used to subtract the disturbance at the input of $G$. The delay constant $d$ and the switching on and off time have to be set in advance, hence $T_d$ must be known. Note that if the disturbance frequency is not a multiple of the sampling frequency $T_s$ then extra care has to be taken when setting the delay and switching times. Multiple periods should preferably be used to get a full number of oscillation within the switching timespan that is switched with a period of $T_s$.

The continues time system in \citep{fujimoto2004repetitive} is defined with the $d_o$ added on the input. External disturbances are better modeled as disturbances added to the system output, therefore this approach has changed the position of $d_o$. However, the observer should still model $d_o$ as if it would be added to the input, see \eqref{eq:sys1}, to maintain cancellation of the harmonics at the input of the system. This assumes that $G$ is linear and that the disturbance is sufficiently described by a sinusoidal, since a sinusoidal added as input to a linear system only results in a change in phase and magnitude of the input.

Using a continues time state space representation the system and the disturbance can be described as follows

\begin{subequations}
  \label{eq:sys12}
  \begin{alignat}{2}
    \label{eq:sys1}
    & \mathbf{\dot{x}}(t) = \mathbf{A_cx}(t) + \mathbf{B_c}(u(t) + d_o(t)) \\
    \label{eq:sys2}
    & y(t) = \mathbf{C_cx}(t)
  \end{alignat}
\end{subequations}

and the disturbance as

\begin{subequations}
  \label{eq:dist12}
  \begin{alignat}{2}
    \label{eq:dist1}
    & \mathbf{\dot{x}}_d(t) = \mathbf{A_dx_d}(t) \\
    \label{eq:dist2}
    & d_o(t) = \mathbf{C_dx_d}(t)
  \end{alignat}
\end{subequations}

where $\mathbf{x}$ and $\mathbf{x_d}$ is the system and disturbance state vector and $\mathbf{A_c, B_c, A_d, C_c}$ and $\mathbf{C_d}$ are known system and disturbance matrices. The Laplace transform of $\frac{1}{w}sin(wt)$ is $1/(s^2 + w^2)$, yielding the state space equations in \eqref{eq:sinm} with zero input.

\begin{equation}
  \label{eq:sinm}
  \mathbf{A_d} =
    \begin{bmatrix}
       0 & 1\\[0.3em]
       -w^2 & 0
     \end{bmatrix}
     \qquad
  \mathbf{C_d} =
    \begin{bmatrix}
        1 & 0\\
    \end{bmatrix}
\end{equation}

The discrete state space representations are obtain by using \eqref{eq:discr123} from \citep{industrial}

\begin{equation}
  \label{eq:discr123}
  A_z = e^{AT_s}  \qquad B_z = \int_{0}^{Ts} e^{AT_s}B dt \qquad C_z = C
\end{equation}

yielding the equations in \eqref{eq:discrsys}

\begin{subequations}
  \label{eq:discrsys}
  \begin{alignat}{2}
    & \mathbf{x_{zs}}[n + 1] = \mathbf{A_{zs}x_{zs}}[n] + \mathbf{B_{zs}}(u_z[n] + d_{zo}[n]) \\
    & y_{zs}[n] = \mathbf{C_{zs}x_{zs}}[n] \\
    & \mathbf{x_{zd}}[n + 1] = \mathbf{A_{zd}x_{zd}}[n]\\
    & d_{zo}[n] = \mathbf{C_{zd}x_{zd}}[n]
  \end{alignat}
\end{subequations}

where the disturbance and input are assumed to be piecewise constant during each sampling period $T_s$.

Lastly, the disturbance is estimated by an observer which is given as

\begin{equation}
  \label{eq:obs}
  \mathbf{\hat{x}}[n + 1] = \mathbf{A\hat{x}}[n] + \mathbf{B}u[n] + \mathbf{K}(y[n] - \mathbf{C\hat{x}}[n])
\end{equation}

where $\mathbf{A, B}$ and $\mathbf{C}$ are the augmented system matrices and $\mathbf{K}$ is the observer gain.

\begin{equation}
  \label{eq:sinm}
  \mathbf{A} =
    \begin{bmatrix}
       \mathbf{A_{zs}} & \mathbf{C_{zd}B_{zs}}\\[0.3em]
       \mathbf{0} & \mathbf{A_{zd}}\\
     \end{bmatrix}
     \qquad
  \mathbf{B} =
    \begin{bmatrix}
        \mathbf{B_{zs}}\\
        \mathbf{0}
    \end{bmatrix}
     \qquad
  \mathbf{C} =
    \begin{bmatrix}
        \mathbf{C_{zs}} & \mathbf{0}\\
    \end{bmatrix}
\end{equation}

The observer gain should be tuned (placing the eigenvalues of $\mathbf{A-KC}$) with respect to the tradeoff between the quickness in the state reconstruction and the sensitivity to measurement noise. An optimal choice of K can be calculated by the Kalman filter if the noise intensities are known. By deriving the closed loop system, it is shown in \citep{fujimoto2004repetitive} that the disturbance rejection will be achieved at every sampling point in steady state.

%\begin{chapter-appendix}
%  \label{ap:lyaponov}

%\section{MRACPE}

%\end{chapter-appendix}
